## 连通外部知识库（以 MaxKB + `nomic_embed_f16` 为例）

### 一、总体思路

- 目标：在 Open WebUI 中使用已接入的 `nomic_embed_f16`，**与外部知识库系统（如 MaxKB）实现联动检索 + 问答**。
- 关键前提：
  - **向量空间必须一致**：MaxKB 自身也要使用 `nomic_embed_f16` 生成并存储向量；
  - Open WebUI 不直接操作 MaxKB 的底层向量库，而是通过 **HTTP API** 调用 MaxKB 的检索/问答接口。

---

### 二、在 MaxKB 中接入 `nomic_embed_f16`

1. **暴露/部署 `nomic_embed_f16` 服务**
   - 要求提供一个可被 MaxKB 调用的 HTTP 接口，例如：
     - `POST /embed`
     - 请求体：`{ "texts": ["...", "..."] }`
     - 响应体：`{ "vectors": [[...], [...]] }`
   - 记录好 Base URL 和鉴权方式（如 API Key）。

2. **在 MaxKB 配置自定义嵌入模型**
   - 在 MaxKB 的「模型管理 / 自定义模型」中新增一个嵌入模型：
     - 名称：`nomic_embed_f16`
     - 类型：Embedding / 向量模型
     - Base URL：指向上述服务
     - 参数映射：告诉 MaxKB 如何将文本数组传给服务、从响应中取回向量。

3. **用该模型重建 / 新建知识库**
   - 在知识库配置中选择 `nomic_embed_f16` 作为该库的「嵌入模型」。
   - 让 MaxKB 对文档执行：
     - 分片（chunking）
     - 向量化
     - 建立向量索引
   - 从此，MaxKB 知识库中的全部向量与 Open WebUI 中的 `nomic_embed_f16` 处于同一向量空间。

---

### 三、Open WebUI 与 MaxKB 的连通方式

#### 1. 调用链设计

- Open WebUI 负责：
  - 用户界面、会话管理、本地大模型（如 DeepSeek 70B）推理；
  - 调用外部工具（MaxKB）获取相关文档片段。
- MaxKB 负责：
  - 知识库管理、文档拆分 + 嵌入 + 向量检索；
  - 提供 HTTP API 返回检索结果或直接问答结果。

#### 2. 推荐模式：MaxKB 检索 + 本地大模型回答

1. 用户在 Open WebUI 中提问（可指定“使用 MaxKB 知识库”）。
2. Open WebUI 调用工具 `MaxKBSearch`：
   - 向 MaxKB 发送 HTTP 请求（如 `POST /api/qa` 或 `POST /api/search`，具体以 MaxKB 文档为准）；
   - 参数：用户问题、目标知识库 ID 等。
3. MaxKB 使用自己的 RAG 流程（含 `nomic_embed_f16` 向量检索）返回：
   - 若干命中的文档片段原文 + 元数据（source、file_id 等）。
4. Open WebUI 将这些片段作为上下文，连同用户问题一起传给本地大模型（如 DeepSeek 70B）生成最终回答。
5. 前端展示：
   - 模型回答；
   - 来自 MaxKB 的引用来源（文档名、段落等）。

#### 3. 另一模式：直接使用 MaxKB 的问答结果

- Open WebUI 只调用 MaxKB 的问答 API，将回答直接呈现或再做轻度重写；
- 优点：计算和检索压力主要在 MaxKB；缺点：与本地大模型的深度融合较少。

---

### 四、工具接口示例（草案）

- 工具名：`MaxKBSearch`
- 请求示例：

```json
POST http://maxkb.example.com/api/qa
{
  "question": "请根据公司内部文档解释一下 X 问题？",
  "knowledge_base_id": "kb-123",
  "top_k": 4
}
```

- 响应示例（供 Open WebUI 使用）：

```json
{
  "answers": [
    {
      "content": "片段原文内容……",
      "source": {
        "title": "某某文档",
        "id": "doc-abc",
        "url": "https://maxkb.example.com/docs/doc-abc"
      }
    }
  ]
}
```

- Open WebUI 将 `answers[*].content` 拼接为上下文，作为系统/工具消息传入本地大模型，`source` 信息用于前端展示引用来源。

---

### 五、小结

- 要在 Open WebUI 中“用 `nomic_embed_f16` 检索 MaxKB 知识库”，**关键不是直接操作向量，而是让 MaxKB 自己用同一个嵌入模型建索引**。  
- Open WebUI 最适合作为「聊天与 AI 中枢」，通过 HTTP 工具方式调用 MaxKB，获取检索到的文档片段，再交给本地大模型生成更自然、更可控的回答。


